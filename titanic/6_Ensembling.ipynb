{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold, KFold, RandomizedSearchCV, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
    "\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "SEED = 42\n",
    "\n",
    "train_ = pd.read_csv(\"assets/train.csv\")\n",
    "test_ = pd.read_csv(\"assets/test.csv\")\n",
    "\n",
    "train = train_.copy()\n",
    "test = test_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: {'PassengerId', 'Survived', 'SibSp', 'Fare', 'Age', 'Parch', 'Pclass'}\n",
      "Categorical Features: {'Cabin', 'Embarked', 'Name', 'Sex', 'Ticket'}\n"
     ]
    }
   ],
   "source": [
    "num_features = set([c for c in train.columns if train[c].dtype != \"object\"])\n",
    "cat_features = set([c for c in train.columns if c not in num_features])\n",
    "print(\"Numerical Features: {}\\nCategorical Features: {}\".format(num_features, cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rare_titles(df):\n",
    "    title = df[\"Title\"]\n",
    "    if title in [\"Capt\", \"Col\", \"Don\", \"Jonkheer\", \"Major\", \"Sir\", \"Rev\"]:\n",
    "        return \"Mr\"\n",
    "    elif title in [\"Mme\", \"th\", \"Lady\", \"Dona\"]:\n",
    "        return 'Mrs'\n",
    "    elif title in [\"Mlle\", \"Ms\"]:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if df['Sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "    \n",
    "def substrings_in_string(big_string, substrings):\n",
    "    if pd.isna(big_string):\n",
    "        return \"Unknown\"\n",
    "    for substring in substrings:\n",
    "        if big_string.find(substring) != -1:\n",
    "            if substring == \"T\":\n",
    "                return \"A\"\n",
    "            else:\n",
    "                return substring\n",
    "            \n",
    "def engineer_numerical_features(df):\n",
    "    temp = df.copy()\n",
    "    \n",
    "    # temp[\"Age\"].fillna(temp[\"Age\"].mean(), inplace=True)\n",
    "    mean = temp[\"Age\"].mean()\n",
    "    std = temp[\"Age\"].std()\n",
    "    is_null = temp[\"Age\"].isnull().sum()\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size=is_null)\n",
    "    ages = temp[\"Age\"].copy()\n",
    "    ages[np.isnan(ages)] = rand_age\n",
    "    temp[\"Age\"] = ages\n",
    "    temp[\"Age\"] = temp[\"Age\"].astype(int)\n",
    "\n",
    "    temp.loc[temp[\"Age\"] <= 18, \"Age\"] = 0\n",
    "    temp.loc[(temp[\"Age\"] > 18) & (temp[\"Age\"] <= 23), \"Age\"] = 1\n",
    "    temp.loc[(temp[\"Age\"] > 23) & (temp[\"Age\"] <= 28), \"Age\"] = 2\n",
    "    temp.loc[(temp[\"Age\"] > 28) & (temp[\"Age\"] <= 34), \"Age\"] = 3\n",
    "    temp.loc[(temp[\"Age\"] > 34) & (temp[\"Age\"] <= 44), \"Age\"] = 4\n",
    "    temp.loc[(temp[\"Age\"] > 44), \"Age\"] = 5\n",
    "\n",
    "    #temp[\"Fare\"].fillna(0, inplace=True)\n",
    "    mean = temp[\"Fare\"].mean()\n",
    "    std = temp[\"Fare\"].std()\n",
    "    is_null = temp[\"Fare\"].isnull().sum()\n",
    "    rand_fare = np.random.randint(mean - std, mean + std, size=is_null)\n",
    "    fares = temp[\"Fare\"].copy()\n",
    "    fares[np.isnan(fares)] = rand_fare\n",
    "    temp[\"Fare\"] = fares\n",
    "    \n",
    "    # Need to fix this binning:\n",
    "\n",
    "    temp.loc[ temp[\"Fare\"] <= 7.775, \"Fare\"] = 0\n",
    "    temp.loc[(temp[\"Fare\"] > 7.775) & (temp[\"Fare\"] <= 8.662), \"Fare\"] = 1\n",
    "    temp.loc[(temp[\"Fare\"] > 8.662) & (temp[\"Fare\"] <= 14.454), \"Fare\"] = 2\n",
    "    temp.loc[(temp[\"Fare\"] > 14.454) & (temp[\"Fare\"] <= 26), \"Fare\"] = 3\n",
    "    temp.loc[(temp[\"Fare\"] > 26) & (temp[\"Fare\"] <= 52.369), \"Fare\"] = 4\n",
    "    temp.loc[ temp[\"Fare\"] > 52.369, \"Fare\"] = 5\n",
    "    temp[\"Fare\"] = temp[\"Fare\"].astype(int)\n",
    "    \n",
    "    family_size = temp[\"SibSp\"] + temp[\"Parch\"]\n",
    "    temp[\"FamilySize\"] = family_size\n",
    "    \n",
    "    fare_per_person = temp[\"Fare\"] / (temp[\"FamilySize\"] + 1)\n",
    "    temp[\"FarePerPerson\"] = fare_per_person\n",
    "    \n",
    "    age_class = temp[\"Age\"] * temp[\"Pclass\"]\n",
    "    temp[\"AgeClass\"] = age_class\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def engineer_categorical_features(df):\n",
    "    temp = df.copy()\n",
    "    \n",
    "    temp[\"Embarked\"].fillna(temp[\"Embarked\"].mode()[0], inplace=True)\n",
    "    \n",
    "    titles = temp[\"Name\"].str.split(', ', expand=True)[1].str.split(\". \", expand=True)[0]\n",
    "    temp[\"Title\"] = titles\n",
    "    temp[\"Title\"] = temp.apply(replace_rare_titles, axis=1)\n",
    "    \n",
    "    #deck = temp[\"Cabin\"].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "    temp[\"Cabin\"] = temp[\"Cabin\"].fillna(\"U0\")\n",
    "    deck = temp[\"Cabin\"].map(lambda x: x[0])\n",
    "    temp[\"Deck\"] = deck\n",
    "    decks = {\"A\": 1, \"T\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "    temp[\"Deck\"] = temp[\"Deck\"].map(decks)\n",
    "    temp[\"Deck\"] = temp[\"Deck\"].astype(int)\n",
    "    \n",
    "#     genders = {\"male\": 0, \"female\": 1}\n",
    "#     temp[\"Sex\"] = temp[\"Sex\"].map(genders)\n",
    "    \n",
    "#     ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "#     temp[\"Embarked\"] = temp[\"Embarked\"].map(ports)\n",
    "    \n",
    "    one_hot_cols = [\"Title\", \"Sex\", \"Embarked\"]\n",
    "    \n",
    "    for o in one_hot_cols:\n",
    "        dummies = pd.get_dummies(temp[o], prefix=o)\n",
    "        temp = pd.concat([temp, dummies], axis=1)\n",
    "    \n",
    "    temp.drop(columns=list(cat_features) + [\"Title\", \"Sex\", \"Embarked\", \"PassengerId\"], inplace=True)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = engineer_numerical_features(train_)\n",
    "test = engineer_numerical_features(test_)\n",
    "train = engineer_categorical_features(train)\n",
    "test = engineer_categorical_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "y = X.pop(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "# kf = KFold(n_splits= NFOLDS, random_state=SEED)\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "rf_random_param = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_random_param, n_iter=100, cv=kfold, random_state=SEED, n_jobs=4)\n",
    "\n",
    "# rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_\n",
    "# rf_random.best_score_ # 0.8305274971941639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_\n",
    "\n",
    "rf_random_p = {'n_estimators': 1000,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 100,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_param = {'n_estimators': [600, 800, 1000, 1200],\n",
    "     'min_samples_split': [3, 5, 7],\n",
    "     'min_samples_leaf': [3, 4, 5, 6],\n",
    "     'max_features': ['auto'],\n",
    "     'max_depth': [80, 90, 100, 110],\n",
    "     'bootstrap': [True]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=SEED)    \n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=rf_grid_param, cv=kfold, n_jobs=4)\n",
    "\n",
    "# rf_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid.best_params_\n",
    "# rf_random.best_score_ # 0.8305274971941639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid.best_params_\n",
    "\n",
    "rf_grid_p = {'bootstrap': True,\n",
    " 'max_depth': 80,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 3,\n",
    " 'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=SEED)\n",
    "rf_baseline.fit(X, y)\n",
    "rf_baseline_results = cross_validate(rf_baseline, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "rf_random = RandomForestClassifier(random_state=SEED, **rf_random_p)\n",
    "rf_random.fit(X, y)\n",
    "rf_random_results = cross_validate(rf_random, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "rf_grid = RandomForestClassifier(random_state=SEED, **rf_grid_p)\n",
    "rf_grid.fit(X, y)\n",
    "rf_grid_results = cross_validate(rf_grid, X, y, cv=kfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.7991818530974149\n",
      "Random: 0.8216352866368984\n",
      "Grid: 0.8216352866368984\n"
     ]
    }
   ],
   "source": [
    "rf_baseline_score = rf_baseline_results[\"test_score\"].mean()\n",
    "rf_random_score = rf_random_results[\"test_score\"].mean()\n",
    "rf_grid_score = rf_grid_results[\"test_score\"].mean()\n",
    "print(\"Baseline: {}\\nRandom: {}\\nGrid: {}\".format(rf_baseline_score, rf_random_score, rf_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline: 0.8100558659217877\n",
    "Random: 0.8156424581005587\n",
    "Grid: 0.8100558659217877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=4,\n",
       "          param_distributions={'loss': ['deviance'], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'learning_rate': [0.15, 0.1, 0.05, 0.01], 'max_depth': [2, 4, 6, 8], 'min_samples_leaf': [75, 100, 125, 150], 'max_features': [0.5, 0.3, 0.1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=SEED)\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "gbc_random_param = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : n_estimators,\n",
    "              'learning_rate': [0.15, 0.1, 0.05, 0.01],\n",
    "              'max_depth': [2, 4, 6, 8],\n",
    "              'min_samples_leaf': [75, 100, 125, 150],\n",
    "              'max_features': [0.5, 0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gbc_random = RandomizedSearchCV(estimator=gbc, param_distributions=gbc_random_param, n_iter=100, cv=kfold, random_state=SEED, n_jobs=4)\n",
    "\n",
    "gbc_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc_random.best_params_\n",
    "# gbc_random.best_score_ # 0.8338945005611672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbc_random.best_params_\n",
    "\n",
    "gbc_random_p = {'n_estimators': 1800,\n",
    " 'min_samples_leaf': 150,\n",
    " 'max_features': 0.5,\n",
    " 'max_depth': 8,\n",
    " 'loss': 'deviance',\n",
    " 'learning_rate': 0.15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=SEED)\n",
    "gbc_grid_param = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [1600, 1800, 2000, 2200],\n",
    "              'learning_rate': [0.2, 0.15, 0.1, 0.05],\n",
    "              'max_depth': [6, 8, 10],\n",
    "              'min_samples_leaf': [125, 150, 175],\n",
    "              'max_features': [0.75, 0.5, 0.25] \n",
    "              }\n",
    "\n",
    "gbc_grid = GridSearchCV(gbc, param_grid=gbc_grid_param, cv=kfold, scoring=\"accuracy\", n_jobs=4)\n",
    "\n",
    "# gbc_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc_grid.best_params_\n",
    "# gbc_grid.best_score_ # 0.8159371492704826 w/o randomizedsearch, 0.8361391694725028 after randomizedsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc_grid.best_params_\n",
    "\n",
    "gbc_grid_p = {'learning_rate': 0.15,\n",
    " 'loss': 'deviance',\n",
    " 'max_depth': 6,\n",
    " 'max_features': 0.75,\n",
    " 'min_samples_leaf': 150,\n",
    " 'n_estimators': 1600}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_baseline = GradientBoostingClassifier(random_state=SEED)\n",
    "gbc_baseline.fit(X, y)\n",
    "gbc_baseline_results = cross_validate(gbc_baseline, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "gbc_random = GradientBoostingClassifier(random_state=SEED, **gbc_random_p)\n",
    "gbc_random.fit(X, y)\n",
    "gbc_random_results = cross_validate(gbc_random, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "gbc_grid = GradientBoostingClassifier(random_state=SEED, **gbc_grid_p)\n",
    "gbc_grid.fit(X, y)\n",
    "gbc_grid_results = cross_validate(gbc_grid, X, y, cv=kfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.8104433419971084\n",
      "Random: 0.8238634336565138\n",
      "Grid: 0.824980752092268\n"
     ]
    }
   ],
   "source": [
    "gbc_baseline_score = gbc_baseline_results[\"test_score\"].mean()\n",
    "gbc_random_score = gbc_random_results[\"test_score\"].mean()\n",
    "gbc_grid_score = gbc_grid_results[\"test_score\"].mean()\n",
    "print(\"Baseline: {}\\nRandom: {}\\nGrid: {}\".format(gbc_baseline_score, gbc_random_score, gbc_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(random_state=SEED)\n",
    "\n",
    "etc_random_param = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 5, 7, 10],\n",
    "              \"min_samples_split\": [2, 3, 5, 7, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 5, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100, 300, 500, 700, 900],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "etc_random = RandomizedSearchCV(estimator=etc, param_distributions=etc_random_param, n_iter=100, cv=kfold, n_jobs=4, random_state=SEED)\n",
    "\n",
    "#etc_random.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc_random.best_params_\n",
    "# etc_random.best_score_ # 0.8316498316498316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc_random.best_params_\n",
    "\n",
    "etc_random_p = {'n_estimators': 900,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 5,\n",
    " 'max_features': 7,\n",
    " 'max_depth': None,\n",
    " 'criterion': 'gini',\n",
    " 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(random_state=SEED)\n",
    "\n",
    "etc_grid_param = {\"max_depth\": [None],\n",
    "              \"max_features\": [6, 8, 10],\n",
    "              \"min_samples_split\": [6, 8, 10, 12],\n",
    "              \"min_samples_leaf\": [3, 5, 7],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[800, 1000, 1200],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "etc_grid = GridSearchCV(etc, param_grid=etc_grid_param, scoring=\"accuracy\", cv=kfold, n_jobs=4)\n",
    "\n",
    "#etc_grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc_grid.best_params_\n",
    "# etc_grid.best_score_ # 0.835016835016835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc_grid.best_params_\n",
    "\n",
    "etc_grid_p = {'bootstrap': False,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': 6,\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 12,\n",
    " 'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "etc_baseline = ExtraTreesClassifier(random_state=SEED)\n",
    "etc_baseline.fit(X, y)\n",
    "etc_baseline_results = cross_validate(gbc_baseline, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "etc_random = ExtraTreesClassifier(random_state=SEED, **etc_random_p)\n",
    "etc_random.fit(X, y)\n",
    "etc_random_results = cross_validate(etc_random, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "etc_grid = ExtraTreesClassifier(random_state=SEED, **etc_grid_p)\n",
    "etc_grid.fit(X, y)\n",
    "etc_grid_results = cross_validate(etc_grid, X, y, cv=kfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.8104433419971084\n",
      "Random: 0.828358099388358\n",
      "Grid: 0.8283896975197063\n"
     ]
    }
   ],
   "source": [
    "etc_baseline_score = etc_baseline_results[\"test_score\"].mean()\n",
    "etc_random_score = etc_random_results[\"test_score\"].mean()\n",
    "etc_grid_score = etc_grid_results[\"test_score\"].mean()\n",
    "print(\"Baseline: {}\\nRandom: {}\\nGrid: {}\".format(etc_baseline_score, etc_random_score, etc_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=SEED)\n",
    "\n",
    "svm_random_param = {'kernel': [\"rbf\", \"linear\"], \n",
    "                  'gamma': [0.001, 0.01, 0.1, 1],\n",
    "                  'C': [0.25, 1, 10, 50, 100, 500, 1000]}\n",
    "\n",
    "svm_random = RandomizedSearchCV(estimator=svm, param_distributions=svm_random_param, n_iter=100, cv=kfold, random_state=SEED, n_jobs=4)\n",
    "\n",
    "# svm_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_random.best_params_\n",
    "# svm_random.best_score_ # 0.8282828282828283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_random.best_params_\n",
    "\n",
    "svm_random_p = {'kernel': 'rbf', 'gamma': 0.01, 'C': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=SEED)\n",
    "\n",
    "svm_grid_param = {'kernel': [\"rbf\"], \n",
    "                  'gamma': [0.05, 0.01, 0.15, 0.2],\n",
    "                  'C': [50, 75, 100, 125, 150]}\n",
    "\n",
    "svm_grid = GridSearchCV(svm, param_grid=svm_grid_param, scoring=\"accuracy\", cv=kfold, n_jobs=4)\n",
    "\n",
    "# svm_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_grid.best_params_\n",
    "# svm_grid.best_score_ # 0.8294051627384961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_grid.best_params_\n",
    "\n",
    "svm_grid_p = {'C': 125, 'gamma': 0.01, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svm_baseline = SVC(random_state=SEED)\n",
    "svm_baseline.fit(X, y)\n",
    "svm_baseline_results = cross_validate(svm_baseline, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "svm_random = SVC(random_state=SEED, **svm_random_p)\n",
    "svm_random.fit(X, y)\n",
    "svm_random_results = cross_validate(svm_random, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "svm_grid = SVC(random_state=SEED, **svm_grid_p)\n",
    "svm_grid.fit(X, y)\n",
    "svm_grid_results = cross_validate(svm_grid, X, y, cv=kfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.827240851879947\n",
      "Random: 0.8171787088882955\n",
      "Grid: 0.8182835441116652\n"
     ]
    }
   ],
   "source": [
    "svm_baseline_score = svm_baseline_results[\"test_score\"].mean()\n",
    "svm_random_score = svm_random_results[\"test_score\"].mean()\n",
    "svm_grid_score = svm_grid_results[\"test_score\"].mean()\n",
    "print(\"Baseline: {}\\nRandom: {}\\nGrid: {}\".format(svm_baseline_score, svm_random_score, svm_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_ensemble = VotingClassifier(estimators=[(\"rf\", rf_grid), \n",
    "                                               (\"gbc\", gbc_grid), \n",
    "                                               (\"etc\", etc_grid)], voting=\"soft\", n_jobs=-1)\n",
    "# voting_ensemble.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yhat = voting_ensemble.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(filename, yhat, save=False):\n",
    "    submission_df = pd.DataFrame(columns=[\"PassengerId\", \"Survived\"])\n",
    "    submission_df[\"PassengerId\"] = test_[\"PassengerId\"]\n",
    "    submission_df[\"Survived\"] = yhat\n",
    "    if save:\n",
    "        submission_df.to_csv(\"submissions/\"+filename, header=True, index=False)\n",
    "    return submission_df\n",
    "\n",
    "filename = \"ensemble_model_rf_gbc_etc.csv\"\n",
    "#submission = generate_submission(filename, yhat, False)\n",
    "#submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://www.kaggle.com/arthurtok/0-808-with-simple-stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(train, y)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c = train.copy()\n",
    "y_train = train_c.pop(\"Survived\").ravel()\n",
    "X_train = train_c.values\n",
    "X_test = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 4),(418, 4)\n"
     ]
    }
   ],
   "source": [
    "et_oof_train, et_oof_test = get_oof(etc_grid, X_train, y_train, X_test)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf_grid, X_train, y_train, X_test)\n",
    "gb_oof_train, gb_oof_test = get_oof(gbc_grid, X_train, y_train, X_test)\n",
    "svc_oof_train, svc_oof_test = get_oof(svm_grid, X_train, y_train, X_test)\n",
    "\n",
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, gb_oof_test, svc_oof_test), axis=1)\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=4,\n",
       "          param_distributions={'n_estimators': [500, 1000, 1500, 2000], 'max_depth': [3, 4, 5], 'min_child_weight': [2, 3, 4], 'gamma': [0.9, 1, 1.1], 'subsample': [0.8, 0.9, 1], 'colsample_bytree': [0.8, 0.9, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(random_state=SEED)\n",
    "\n",
    "gbm_random_params = {\n",
    "    \"n_estimators\": [500, 1000, 1500, 2000],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"min_child_weight\": [2, 3, 4],\n",
    "    \"gamma\": [0.9, 1, 1.1],\n",
    "    \"subsample\": [0.8, 0.9, 1],\n",
    "    \"colsample_bytree\": [0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "gbm_random = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_random_params, n_iter=100, cv=kfold, random_state=SEED, n_jobs=4)\n",
    "\n",
    "# gbm_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8361391694725028"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gbm_random.best_params_\n",
    "# gbm_random.best_score_ # 0.8361391694725028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbm_random.best_params_\n",
    "\n",
    "gbm_random_p = {'subsample': 1,\n",
    " 'n_estimators': 1500,\n",
    " 'min_child_weight': 4,\n",
    " 'max_depth': 5,\n",
    " 'gamma': 1.1,\n",
    " 'colsample_bytree': 0.9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'n_estimators': [1200, 1400, 1600, 1800], 'max_depth': [4, 5, 6], 'min_child_weight': [3, 4, 5], 'gamma': [1, 1.1, 1.2], 'subsample': [0.9, 1], 'colsample_bytree': [0.8, 0.9, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(random_state=SEED)\n",
    "\n",
    "gbm_grid_params = {\n",
    "    \"n_estimators\": [1200, 1400, 1600, 1800],\n",
    "    \"max_depth\": [4, 5, 6],\n",
    "    \"min_child_weight\": [3, 4, 5],\n",
    "    \"gamma\": [1, 1.1, 1.2],\n",
    "    \"subsample\": [0.9, 1],\n",
    "    \"colsample_bytree\": [0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "gbm_grid = GridSearchCV(gbm, param_grid=gbm_grid_params, cv=kfold, scoring=\"accuracy\", n_jobs=4)\n",
    "\n",
    "gbm_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372615039281706"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gbm_grid.best_params_\n",
    "# gbm_grid.best_score_ # 0.8372615039281706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbm_grid.best_params_\n",
    "\n",
    "gbm_grid_p = {'colsample_bytree': 0.9,\n",
    " 'gamma': 1.1,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 4,\n",
    " 'n_estimators': 1200,\n",
    " 'subsample': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.9, gamma=1.1,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=4, missing=None, n_estimators=1200, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=42,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_submission = xgb.XGBClassifier(random_state=SEED, **gbm_grid_p)\n",
    "gbm_submission.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = gbm_submission.predict(test)\n",
    "\n",
    "filename = \"stacked_model.csv\"\n",
    "submission = generate_submission(filename, yhat, True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
